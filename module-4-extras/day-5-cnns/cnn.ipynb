{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center'>Convolutional Neural Networks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are CNNs used for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src=\"https://www.youtube.com/embed/ACmydtFDTGs\", width='622', height='466')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are mainly used for image recognition/classification. They can be used for video analysis, NLP (sentiment analysis, topic modeling), and speech recognition. Today we'll be discussing how CNNs are you used to classify images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do our brains see an image? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We might see some fluffy tail, a wet nose, flappy ears, and a good boy and conclude we are probably seeing dog. There is not one singular thing about a dog that our brain recognizes as a dog but an amalgamation of different patterns that allow us to make a probable guess.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/chihuahua.jpeg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutal Neural Networks - How computers see images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/architecture.jpeg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To computers images are a 3D object - composed of 3 matrices - one for each primary color that can be combined in varying intensities to create different colors. Each element in a matrix represents the location of a pixel and contains a number between 0 and 255 which indicates the intensity of the corresponding primary color in that pixel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From wikipedia:\n",
    "\n",
    "    \"The RGB color model is an additive color model[1] in which red, green and blue light are added together in various ways to reproduce a broad array of colors. The name of the model comes from the initials of the three additive primary colors, red, green, and blue. The main purpose of the RGB color model is for the sensing, representation, and display of images in electronic systems, such as televisions and computers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/rgb.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we want CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/NN_vs_CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/weight_sharing_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To Convolve means to roll together</b><br/><br/>\n",
    "In the context of mathematics think of it as a way of mixing two functions by multiplying them.<br/><br/>\n",
    "\n",
    "Convolutional neural networks make use of linear algebra to identify patterns using the pixel values (intensity of R,G, or B). By taking a small matrix and moving it across an image and multiplying them together every time it moves our network can mathematically identify patterns in these images. This small matrix is known as a <b>\"kernel\"</b> or <b>\"filter\"</b> and each one is designed to identify a particular pattern in an image (edges, shapes, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/convolve.gif' width='300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/conv.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a filter is \"rolled over\" an image the resulting matrix is called a <b>Feature Map</b> - literally a map of where each pattern of feature is in the image. Elements with higher values indicate the presence of that pattern the filter is looking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values (or weights) of the filter are adjusted during back-propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every node in a neural network layer is a different filter looking for a certain pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Typically use 3X3 maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For N⨉N input and kernel size k⨉k the output size is M = N - k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Parameters</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Padding</b> - Sometimes it is convenient to pad the input volume with zeros around the border. Helps with detecting patterns at the edge of an image. \n",
    "\n",
    "- Padding 'SAME' - keeps image the same size (k-1/2 on each side for map sized k) \n",
    "- Padding 'VALID' - padding is 0.\n",
    "\n",
    "Padding is used to control resolution in the output layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Stride</b> - The number of pixels to shift the filter on each \"roll\". The larger the stride the smaller the feature map will be - but we will lose more information.\n",
    "\n",
    "Used for:\n",
    " - faster processsing\n",
    " - invariance to translation\n",
    " \n",
    "$Output = \\frac{I + 2pad - map}{stride} + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature maps are fed into a max pool layer, and like convolutions, this method is applied one patch at a time (usually 2x2). Max pooling simply takes the largest value from one patch of an image, places it in a new matrix next to the max values from other patches, and discards the rest of the information contained in the activation maps. Other methods exist such as average pooling (taking an average of the patch). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/maxpool.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This process results in a new feature map with reduced dimensionality that is then passed into another convolution layer to continue the pattern finding process. These steps are repeated until they are passed to a fully connected layer that proceeds to classify the image using the identified patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used for:\n",
    "    - invarince for translation\n",
    "    - faster processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for high resolution to reduce complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Output = \\frac{I + 2pad - map'}{stride} + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$map' = map + (map-1)*(dilate - 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the neural networks has collected a series of patterns that an image contains it is ready to make a guess as to what the image is. In order to do so, it starts by flattening the 2D matrix into a 1D vector, so it can be passed into a normal densely connected layer for classification. Then using this vector one or many densely connected layers will make a prediction as to what the image is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/typical_CNN.png\" width=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning is the process of training the last few layers of a pre-trained model to make classifications for a specific use case. This is not exclusive to CNNs but can be applied other neural networks and ML models. Pre-trained CNN models have dozens to hundreds of layers that have been trained on millions of images. Through this training they are very good at identifying complex patterns in image and these collection of patterns can then be used to train the final densely connected layers to make a specific classification. Examples of these pre-trained models include ResNet, InceptionNet, VGG16 - many of which are available through Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G96i9Pql73uM",
    "outputId": "916d9b1f-7d21-4fe1-bbeb-b24bd9f66766"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9na1fhXDRcu"
   },
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5cs_btuEPgpM",
    "outputId": "900dd0e7-d017-4162-cd16-9313f2d93226"
   },
   "outputs": [],
   "source": [
    "# download from https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/download\n",
    "!unzip data/hot-dog-not-hot-dog.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqt9Rx1KDqGg"
   },
   "source": [
    "## Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s8T5QO9573uv",
    "outputId": "a5d8296d-3980-4e80-b943-057200db4e25",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all the data in the directory split/test, and reshape them\n",
    "data_te = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=4419,\n",
    "    seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0MgTcB1K388K",
    "outputId": "022b3799-eb29-45d2-f5c1-2ba597f4bad3"
   },
   "outputs": [],
   "source": [
    "data_tr = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=4419,\n",
    "    seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKWqCS0K73u1"
   },
   "outputs": [],
   "source": [
    "#split images and labels\n",
    "images_tr, labels_tr = next(data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "okDFvQJlmt0S",
    "outputId": "8fd96008-718a-4125-b681-4f7ff6d4df67"
   },
   "outputs": [],
   "source": [
    "images_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sH9Z4IF44Rht"
   },
   "outputs": [],
   "source": [
    "#split images and labels\n",
    "images_te, labels_te = next(data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_G9eBDm_4Uv_"
   },
   "outputs": [],
   "source": [
    "images = np.concatenate((images_tr, images_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qb_D17U_4eJ0"
   },
   "outputs": [],
   "source": [
    "labels = np.concatenate((labels_tr[:,0], labels_te[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "Fcb6x5uE73u5",
    "outputId": "4194c044-476b-48bb-d8f3-908da34704a4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[28])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czJtmSRk3cXh"
   },
   "source": [
    "## 3. Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "898G-tvC73wb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_model, X_test, y_model, y_test = train_test_split(images, labels, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryysKVws73wd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zw0LD8xe73wf"
   },
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      input_shape=(224, 224,  3),\n",
    "                      padding='SAME'))\n",
    "# 64 bias parameters\n",
    "# 64 * (3 * 3 * 3) weight parametrs\n",
    "# Output is 64*224*224\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "# Output is 64*112*112\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "# 32 bias parameters\n",
    "# 32 * (3*3*64)\n",
    "# Output is 32*112*112\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "            optimizer=\"sgd\",\n",
    "            metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N0TyaG2cSn82"
   },
   "outputs": [],
   "source": [
    "saving_weights = keras.callbacks.ModelCheckpoint(\n",
    "    'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    monitor='val_loss', verbose=0, save_best_only=False,\n",
    "    save_weights_only=False, mode='auto', period=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBKf5V1CSvZV"
   },
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=20,\n",
    "    verbose=0, mode='auto', min_delta=0.0001, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLFrLlbeSxFO"
   },
   "outputs": [],
   "source": [
    "nan_problem = keras.callbacks.TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3__e9-5TQon"
   },
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=20,\n",
    "    verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ep8osdqUTZ_Z"
   },
   "outputs": [],
   "source": [
    "csv_logger = keras.callbacks.CSVLogger('training.log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "mx6119KJ5ox_",
    "outputId": "cd9476c1-8beb-4f3d-fdf9-dfa764275da3"
   },
   "outputs": [],
   "source": [
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oFim3wbY73wv",
    "outputId": "5e4fa080-82f4-466d-af80-65965257f10d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn1 = cnn.fit(X_train,\n",
    "               y_train,\n",
    "               epochs=2,\n",
    "               batch_size=200,\n",
    "               validation_data=(X_val, y_val),\n",
    "               callbacks=[csv_logger, early_stop, nan_problem, reduce_lr, saving_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "fV2LHFpZ73wy",
    "outputId": "367181cc-eb10-4382-b7ff-c8b7a5673c88"
   },
   "outputs": [],
   "source": [
    "hist_cnn = cnn1.history\n",
    "loss_values = hist_cnn['loss']\n",
    "val_loss_values = hist_cnn['val_loss']\n",
    "acc_values = hist_cnn['acc']\n",
    "val_acc_values = hist_cnn['val_acc']\n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "JAd1W7eg73w3",
    "outputId": "e62eb046-2f6f-4307-e511-aa2d599efcbe"
   },
   "outputs": [],
   "source": [
    "results_train = cnn.evaluate(X_train, y_train)\n",
    "results_test = cnn.evaluate(X_test, y_test)\n",
    "print(results_train, results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWuNQvErXERw"
   },
   "outputs": [],
   "source": [
    "# This should load a weight file in, but I can't seem to figure out how to make this work\n",
    "# cnn.load_weights(\"weights.20-0.75.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mhOR2cULXt0g",
    "outputId": "6b82ce88-95a3-40d6-be94-dc58f8d75126"
   },
   "outputs": [],
   "source": [
    "# cnn.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5_EvP8L3wOC"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faebp_jJQCcQ"
   },
   "source": [
    "### InceptionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khtt-CRtQK6A"
   },
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQbTTZCc5XJr"
   },
   "outputs": [],
   "source": [
    "imagenet = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "imagenet_new = imagenet.output\n",
    "new_model = models.Sequential()\n",
    "new_model.add(imagenet)\n",
    "new_model.add(GlobalAveragePooling2D())\n",
    "new_model.add(Dense(1024, activation='relu'))\n",
    "new_model.add(Dense(1024, activation='relu'))  # dense layer 2\n",
    "new_model.add(Dense(512, activation='relu'))  # dense layer 3\n",
    "# final layer with softmax activation\n",
    "new_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OM6d6ywG3qse",
    "outputId": "0a794b29-b664-4d39-d233-0f61bac4a385"
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(imagenet.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "8pDfw1J7_e9W",
    "outputId": "3245e403-579d-45cf-e556-18c11c24752d"
   },
   "outputs": [],
   "source": [
    "for i,layer in enumerate(new_model.layers):\n",
    "    print(i,layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juyAVvVC_3YQ"
   },
   "outputs": [],
   "source": [
    "for layer in new_model.layers[:1]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ACKbZrP6ACao",
    "outputId": "40907635-5b18-41a8-b8af-6ea84d7051cc"
   },
   "outputs": [],
   "source": [
    "for i,layer in enumerate(new_model.layers):\n",
    "    print(i,layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "e2TFnnh3AKm9",
    "outputId": "a6bae237-a437-4cf8-9453-73f965fafd89"
   },
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# step_size_train=train_generator.n//train_generator.batch_size\n",
    "new_model.fit(X_train,\n",
    "              y_train,\n",
    "              epochs=10,\n",
    "              batch_size=50,\n",
    "              validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "T_C-Byd5BJ5w",
    "outputId": "4a49ef61-54c6-4476-d84d-fcb2ab6c8366"
   },
   "outputs": [],
   "source": [
    "new_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSSImG_1BtIP"
   },
   "outputs": [],
   "source": [
    "predictions_transfer = new_model.predict(X_test)\n",
    "predictions_transfer = np.around(predictions_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e1Y387LFBhGm",
    "outputId": "b0a844f5-918e-4a42-c67c-597c4ec89045"
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, predictions_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7gLauC_CQcL"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "66ZssBELZRzX",
    "outputId": "a05de45e-c80b-46a7-ddb8-e53235441b25"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predictions_transfer), classes=['hot dog', 'not hot dog'], normalize=False,\n",
    "                      title='Confusion matrix - ImagenetV3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1slHFBe13-Ab"
   },
   "outputs": [],
   "source": [
    "def predictoneimage_cnn(model, path):\n",
    "    img = load_img(path, target_size=(224, 224))\n",
    "    plt.imshow(img)\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    predict = model.predict(img)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "CbhMvzw87sW7",
    "outputId": "0d05bb11-92ae-47cd-d41e-302ce1d561d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictoneimage_cnn(new_model, '/content/hot-dog-not-hot-dog/test/not_hot_dog/13719.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://skymind.ai/wiki/convolutional-network\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
