{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Forecasting with LSTM Neural Networks\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Learn how to build a basic LSTM using Keras.\n",
    "- Train the LSTM model on unemployment data and forecast to future data.\n",
    "- Understand the different ways to fit the LSTM model for timeseries data.\n",
    "- Understand the \"stateful\" LSTM setup and how it compares to the standard fitting procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction](#introduction)\n",
    "\t- [A note on the lesson content](#a-note-on-the-lesson-content)\n",
    "- [Load the Keras modules](#load-the-keras-modules)\n",
    "- [Prepare the unemployment data for timeseries modeling](#prepare-the-unemployment-data-for-timeseries-modeling)\n",
    "\t- [Create the first-order differenced unemployment rate](#create-the-first-order-differenced-unemployment-rate)\n",
    "\t- [Normalize the differenced unemployement data with `MinMaxScaler`](#normalize-the-differenced-unemployement-data-with-minmaxscaler)\n",
    "\t- [Split the timeseries into 50% train/test splits](#split-the-timeseries-into--traintest-splits)\n",
    "- [Write a function to create the predictor and target data](#write-a-function-to-create-the-predictor-and-target-data)\n",
    "\t- [Create training and testing data for a lag of 1](#create-training-and-testing-data-for-a-lag-of-)\n",
    "- [Reshape the data to work with the LSTM](#reshape-the-data-to-work-with-the-lstm)\n",
    "- [Constructing the Keras model](#constructing-the-keras-model)\n",
    "\t- [Fit the LSTM model](#fit-the-lstm-model)\n",
    "\t- [Plot the original data, the training predictions and the testing predictions](#plot-the-original-data-the-training-predictions-and-the-testing-predictions)\n",
    "- [LSTM with multiple lags as predictors](#lstm-with-multiple-lags-as-predictors)\n",
    "- [Refraing the problem using the LSTM \"time steps\" dimension](#refraing-the-problem-using-the-lstm-time-steps-dimension)\n",
    "\t- [Rebuild and fit the LSTM model, and plot the predictions](#rebuild-and-fit-the-lstm-model-and-plot-the-predictions)\n",
    "- [\"Stateful\" LSTM models](#stateful-lstm-models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## Introduction\n",
    "---\n",
    "\n",
    "Modeling timeseries and forecasting with neural networks is a growing trend. The Long Short Term Memory (LSTM) recurrent neural network architecture is a popular choice when \"context\" or memory across time is a desired capability of the model.\n",
    "\n",
    "In this walkthrough/codealong lecture we will be building an LSTM using the Keras framework to forecast stock market timeseries data. \n",
    "\n",
    "<a id=\"a-note-on-the-lesson-content\"></a>\n",
    "### A note on the lesson content\n",
    "\n",
    "This codealong focuses primarily on the Keras implementation and application of LSTM neural networks. This lecture does not cover:\n",
    "- The theory behind recurrent neural networks.\n",
    "- The mathematics or theory behind the architecture of LSTM networks.\n",
    "\n",
    "There are a variety of great resources to dive deeper into LSTM networks:\n",
    "- [A beginners guide to recurrent networks and LSTMs](http://deeplearning4j.org/lstm.html#a-beginners-guide-to-recurrent-networks-and-lstms)\n",
    "- [Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [This tutorial provides a great introduction to building a simple LSTM for timeseries forecasting.](http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/) which \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare-the-unemployment-data-for-timeseries-modeling\"></a>\n",
    "## Prepare the unemployment data for timeseries modeling\n",
    "---\n",
    "\n",
    "First we will load quarterly US unemployment data to do some basic forecasting using LSTMs. \n",
    "\n",
    "**Load the unemployment data from CSV file and perform any required cleaning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/seasonally-adjusted-quarterly-us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternatively\n",
    "data = pd.read_csv('https://git.generalassemb.ly/Gopinaath/Unit-5_Gopi/raw/master/dsi-unit-5.09-nnet-timeseries_forecasting_lstms-lesson/datasets/seasonally-adjusted-quarterly-us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['year_quarter', 'unemployment_rate']\n",
    "data['unemployment_rate'] = data['unemployment_rate'].map(lambda x: float(str(x).replace('%','')))\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year_quarter'] = data['year_quarter'].apply(lambda x: x.replace('Q1','-03-31')\n",
    "                                                             .replace('Q2','-06-30')\n",
    "                                                             .replace('Q3','-09-30')\n",
    "                                                             .replace('Q4','-12-31'))\n",
    "\n",
    "data['year_quarter'] = data['year_quarter'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('year_quarter',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['unemployment_rate'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['unemployment_rate'].head(4*5).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "res = seasonal_decompose(data['unemployment_rate'])\n",
    "res.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-the-first-order-differenced-unemployment-rate\"></a>\n",
    "### Create the first-order differenced unemployment rate\n",
    "\n",
    "In timeseries modeling the raw timeseries is rarely used. Typically we will use the first order differenced timeseries (or further order differences). Technically this differencing is done to ensure that the timeseries is stationary. \n",
    "\n",
    "However, there are more intuitive reasons why we would want to model the differences as opposed to the actual values. Take the AAPL stock price, for example, and imagine we are a day-trader. If we hold the AAPL stock, we are of course interested in having a model that can predict the price of the stock in the future. However, what we are *really* interested in is how the stock price will *change* in the future from the current point. It is more useful to say \"the stock will go up by one point\" than it is to say \"the stock price will be 51.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['udiff'] = data['unemployment_rate'].diff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"normalize-the-differenced-unemployement-data-with-minmaxscaler\"></a>\n",
    "### Normalize the differenced unemployement data with `MinMaxScaler`\n",
    "\n",
    "We want the rate to be restricted to the range -1 to 1.\n",
    "\n",
    "> **Note:** the differencing will make the first value of the series a NaN value. Make sure to drop this from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urate = data[['udiff']]\n",
    "mms = MinMaxScaler(feature_range=(-1, 1))\n",
    "urate = mms.fit_transform(urate)\n",
    "print(urate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['udiff'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split-the-timeseries-into--traintest-splits\"></a>\n",
    "### Split the timeseries into 50% train/test splits\n",
    "\n",
    "We don't want a random train/test split in this case. With timeseries data, we are interested in how are model generalizes to future data in particular. Make the test set the second half of the data through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(urate) * 0.50)\n",
    "test_size = len(urate) - train_size\n",
    "print(len(urate), train_size, test_size)\n",
    "\n",
    "train, test = urate[0:train_size,:], urate[train_size:len(urate),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"write-a-function-to-create-the-predictor-and-target-data\"></a>\n",
    "## Write a function to create the predictor and target data\n",
    "---\n",
    "\n",
    "The function will need to create a Y target and X predictor. The X predictor matrix will simply be the shifted versions of Y, our target unemployment timeseries. In other words, we want our features to be previous timesteps of the target data for given lags.\n",
    "\n",
    "**Make a function with two arguments:**\n",
    "1. The timeseries data.\n",
    "2. The number of lags of the timeseries to have as predictors.\n",
    "\n",
    "The default should create a dataset where X is the unemployment rate a given time (t) and Y is the unemployment rate at the next time (t + 1). At the default lag of 1 X will just be the unemployment timeseries of Y shifted back by 1.\n",
    "\n",
    "> **Note:** make sure that the output X and Y are of the same length! You will need to slice off a row (at least - depends on the lag order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udiff = data.udiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udiff = udiff[0:8]\n",
    "udiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict(y=udiff.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(timeseries, lag=1, as_array=True):\n",
    "    if not isinstance(timeseries, pd.Series):\n",
    "        timeseries = pd.Series(timeseries.ravel())\n",
    "    y = timeseries[lag:]\n",
    "    X = pd.DataFrame({'lag'+str(lag-i):timeseries.shift(-i) for i in range(0, lag)}).dropna().iloc[:-1, :]\n",
    "    if not as_array:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data(udiff, lag=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-training-and-testing-data-for-a-lag-of-\"></a>\n",
    "### Create training and testing data for a lag of 1\n",
    "\n",
    "Again, this means our X will just have 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 1\n",
    "trainX, trainY = create_data(train, lag)\n",
    "testX, testY = create_data(test, lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reshape-the-data-to-work-with-the-lstm\"></a>\n",
    "## Reshape the data to work with the LSTM\n",
    "---\n",
    "\n",
    "The format of data the LSTM expects is:\n",
    "\n",
    "    [samples, time_steps, features]\n",
    "    \n",
    "Which is a 3D matrix.\n",
    "\n",
    "We have been using 2D predictor matrices for our machine learning algorithms, where our X predictor matrix has been in the form:\n",
    "\n",
    "    [samples, features]\n",
    "\n",
    "Since we are working with timeseries (which is the data an LSTM expects), we are now required to provide information about the time.\n",
    "\n",
    "You can use the `np.reshape()` command to turn your 2D X matrix into a 3D matrix that works for the LSTM matrix. We will talk about the \"time step\" dimension more down the line. \n",
    "\n",
    "> **Note:** In the case of a single lag this time step dimension is redundant. Later on, when we redesign the X matrix so that our individual features have multiple timesteps, this 3D format requirement will be clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"constructing-the-keras-model\"></a>\n",
    "## Constructing the Keras model\n",
    "\n",
    "Our LSTM model will be constructed in three parts.\n",
    "\n",
    "First initialize the sequential layer-to-layer neural network model:\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "```\n",
    "    \n",
    "Add an LSTM layer with 4 blocks/cells/neurons. We specify the `input_shape` to be the same dimensions as our features. You will notice that the `input_shape` below takes a tuple `(None, lag)`. The `None` is a placeholder for the timesteps of our features. By putting `None` we are simply avoiding specifying the timesteps.\n",
    "\n",
    "```python\n",
    "model.add(LSTM(4, input_shape=(None, lag)))\n",
    "```\n",
    "\n",
    "Add the output layer as a layer of one neuron that is fully connected to all of the previous LSTM cells:\n",
    "\n",
    "```python\n",
    "model.add(Dense(1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(None, lag)))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fit-the-lstm-model\"></a>\n",
    "### Fit the LSTM model\n",
    "\n",
    "We can fit the model with these commands:\n",
    "\n",
    "```python\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "```\n",
    "\n",
    "Which will use the squared error loss (regression) and fit the data over 100 \"epochs\", or passes over the training data. It makes multiple passes because these LSTM neural networks learn according to a learning rate (which we have not specified).\n",
    "\n",
    "The `optimizer='adam'` selects the type of algorithm for gradient descent. The Adam optimizer performs well and is often recommended for many types of neural network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plot-the-original-data-the-training-predictions-and-the-testing-predictions\"></a>\n",
    "### Plot the original data, the training predictions and the testing predictions\n",
    "\n",
    "You can predict from a Keras model much like with a sklearn model:\n",
    "\n",
    "```python\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "```\n",
    "\n",
    "Make sure you lag the data forward for training and testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(urate)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[lag:len(trainPredict)+lag, :] = trainPredict\n",
    " \n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(urate)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[-len(testPredict):, :] = testPredict\n",
    " \n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(urate)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lstm-with-multiple-lags-as-predictors\"></a>\n",
    "## LSTM with multiple lags as predictors\n",
    "---\n",
    "\n",
    "We can instead predict the unemployment rate from not just the rate prior, but the `t-1`, `t-2`, and `t-3` rates.\n",
    "\n",
    "You can use the function you wrote above to construct a new X and y where X now has 3 predictors according to the different lags.\n",
    "\n",
    "Create the new Y and X variables below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_data(train, lag)\n",
    "testX, testY = create_data(test, lag)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "print(trainX[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(None, lag)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(urate)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[lag:len(trainPredict)+lag, :] = trainPredict\n",
    " \n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(urate)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[-len(testPredict):, :] = testPredict\n",
    " \n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(urate)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refraing-the-problem-using-the-lstm-time-steps-dimension\"></a>\n",
    "## Refraing the problem using the LSTM \"time steps\" dimension\n",
    "---\n",
    "\n",
    "Recall that our X matrix is converted to the form:\n",
    "\n",
    "    [samples, time steps, features]\n",
    "    \n",
    "In the model we just made, we were saying that we had 3 different features, each of 1 time step long. This works fine, but it would be more appropriate to say that we had 1 feature with three different time steps, since that's what the data actually is (the unemplyment rate lagged to different degrees).\n",
    "\n",
    "Instead of reshaping our data where the time step dimension is 1, we can instead reshape it so that the feature dimension is 1 and the time step dimension is 3, like so:\n",
    "\n",
    "```python\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "```\n",
    "\n",
    "In this toy example, this will for all intents and purposes be the same, but it is more appropriate to specify it this way since the variable is the same.\n",
    "\n",
    "Recreate your training and testing data but reshaping your lags on the time dimension rather than the feature dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 3\n",
    "trainX, trainY = create_data(train, lag)\n",
    "testX, testY = create_data(test, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rebuild-and-fit-the-lstm-model-and-plot-the-predictions\"></a>\n",
    "### Rebuild and fit the LSTM model, and plot the predictions\n",
    "\n",
    "You will need to change the `input_shape` now to be `input_shape=(lag, 1)`, which indicates we have \"lag\" number of timesteps and 1 predictor/feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(lag, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(urate)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[lag:len(trainPredict)+lag, :] = trainPredict\n",
    " \n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(urate)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[-len(testPredict):, :] = testPredict\n",
    " \n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(urate)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
